{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eed9ee3",
   "metadata": {},
   "source": [
    "# Rclone Installation on AppStream (Windows)\n",
    "\n",
    "This report instructs how to build a Windows image with Rclone installed. Please follow the [Sleap-Windows-Report](./Sleap-Windows-Report.ipynb) for instructions on installing Sleap on Windows Image as well as a more detailed guide through the image building process for Windows.\n",
    "\n",
    "- [Windows Build Image Instruction](#Windows-Build-Image-Instruction)\n",
    "- [Windows User Instruction](#Windows-User-Instruction)\n",
    "- [Optional: How to Transfer Files between S3 with Rclone](#Optional:-How-to-Transfer-files-between-S3-buckets-with-Rclone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae651b15",
   "metadata": {},
   "source": [
    "## Windows Build Image Instruction\n",
    "\n",
    "See [Image Builder Guide](/AppStream_Image_Builder_Guide.ipynb) for an overview and explanation of each step, or see [Sleap-Windows-Report](./Sleap-Windows-Report.ipynb) for a more detailed run through each step. \n",
    "\n",
    "**Reminder**: Your image builder instance and/or fleet instances need to have an IAM role with S3 access attached, so that AppStream would create the `appstream-machine-role` profile for rclone to access the S3 buckets. \n",
    "\n",
    "### Admin User Install Package Step\n",
    "\n",
    "    # Open Anaconda Prompt as Administrator: install choco\n",
    "    @\"%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command \"iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\" && SET \"PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin\"\n",
    "    \n",
    "    # Open Anaconda Prompt as usual:\n",
    "    choco install rclone -y\n",
    "    choco install winfsp -y\n",
    "    \n",
    "    # Create file C:\\rclone\\rclone.conf with contents:\n",
    "    [s3]\n",
    "    type = s3\n",
    "    provider = AWS\n",
    "    env_auth = true\n",
    "    region = us-west-2\n",
    "    profile = appstream_machine_role\n",
    "\n",
    "Create Session Scripts to automate mounting buckets when users start an instance. Optionally, you can designate a location for log files for the mount command. \n",
    "\n",
    "    # Create empty directory for log files\n",
    "    mkdir c:\\rclone\\logs\n",
    "    \n",
    "    # Create C:\\rclone\\mount.bat file\n",
    "    @echo off\n",
    "    set RCLONE_PATH=\"C:\\ProgramData\\chocolatey\\bin\\rclone.exe\"\n",
    "    set MOUNT_SOURCE=s3:aind-appstream-data-dev-temporary\n",
    "    set MOUNT_DESTINATION=\"C:\\s3-mount\"\n",
    "    set LOG_FILE=\"C:\\rclone\\logs\\sync_files.txt\"\n",
    "    set RCLONE_CONFIG=\"C:\\rclone\\rclone.conf\"\n",
    "\n",
    "    %RCLONE_PATH% mount %MOUNT_SOURCE% %MOUNT_DESTINATION% --no-console --log-file %LOG_FILE% --config %RCLONE_CONFIG%\n",
    "    @echo on\n",
    "    \n",
    "    # Open Anaconda Prompt as administrator, Edit contents of /appstream/SessionScripts/config.json \n",
    "        {\n",
    "      \"SessionStart\": {\n",
    "        \"executables\": [\n",
    "          {\n",
    "            \"context\": \"user\",\n",
    "            \"filename\": \"C:\\\\rclone\\\\mount.bat,\n",
    "            \"arguments\": \"\",\n",
    "            \"s3LogEnabled\": false\n",
    "          }\n",
    "        ],\n",
    "        \"waitingTime\": 30\n",
    "      },\n",
    "\n",
    "### Template User Default Settings Step\n",
    "    \n",
    "`setx RCLONE_CONFIG 'C:\\rclone\\rclone.conf'`\n",
    "\n",
    "The default rclone config file location is set as an environment variable, so that users can mount buckets without setting the config file flag. However, this will not be necessary in deployment since users are not expected to mount buckets on their own\n",
    "\n",
    "### Test User Testing Step\n",
    "\n",
    "You may mount and unmount buckets to test rclone, but do not expect the session script to be in effect at this phase. The session scripts will take effect when user instances are initiated. \n",
    "\n",
    "    rclone mount s3:aind-appstream-data-dev-temporary MOUNT_PATH --no-console\n",
    "    taskkill /F /IM rclone.exe\n",
    "    \n",
    "    \n",
    "### Admin User Optimization Step\n",
    "\n",
    "Nothing extra is required. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc812061",
   "metadata": {},
   "source": [
    "\n",
    "## Windows User Instruction\n",
    "\n",
    "\n",
    "Here are some instructions if the user may wish to mount S3 buckets via rclone. In deployment, common buckets would already be installed in the image. \n",
    " \n",
    "    \n",
    "### Mount and unmount s3 bucket (Optional)\n",
    "    \n",
    "The difference between using rclone in Linux and Windows is that in Windows, you should *not* create the mount directory beforehand, and the daemon flag is not available so background process is realize by the ampersand. The config file path must be set manually by the flag `--config-file c:\\rclone\\rclone.conf` or by setting the environment variable `RCLONE_CONFIG`, as done in this demo. The `--no-console` flag can be used to hide the console that runs the rclone command, the user would then have to use `taskkill /F /IM rclone.exe` to kill all rclone instances. \n",
    "\n",
    "    # mount s3 bucket in foreground\n",
    "    rclone mount s3:aind-appstream-data-dev-temporary MOUNT_PATH\n",
    "    \n",
    "    # unmount s3 bucket in foreground\n",
    "    [ctrl] + [C]\n",
    "    \n",
    "    # mount s3 bucket in background\n",
    "    rclone mount s3:aind-appstream-data-dev-temporary MOUNT_PATH --no-console\n",
    "    \n",
    "    # unmount all s3 buckets in background\n",
    "    taskkill /F /IM rclone.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ae9b2",
   "metadata": {},
   "source": [
    "### Optional: How to Transfer files between S3 buckets with Rclone\n",
    "\n",
    "To test the performance of Sleap on AppStream instances, you may wish to analyze some large video files on S3. During this demo, I used Rclone to transfer a large video file to our appstream bucket for testing. \n",
    "\n",
    "**Transfer S3 data between buckets with 2 accounts**\n",
    "\n",
    "In rclone.conf file, enter two AWS credentials with names `remoteprod` and `remotetest`. `remoteprod` credentials have read access to the video file, and `remotetest` credentials have write access to the appstream bucket. \n",
    "\n",
    "    git clone https://github.com/rclone/rclone.git\n",
    "    cd rclone\n",
    "    go build\n",
    "    \n",
    "    ./rclone copy \"remoteprod:aind-behavior-data/pose_estimation_training/DLC annotation/1051155866_524760_20200917.behavior-Shailaja-2023-06-19/videos/1051155866_524760_20200917.behavior.mp4\" \"remotetest:aind-appstream-data-dev-temporary\" --config rclone.conf\n",
    "\n",
    "    ./rclone ls remotetest:aind-appstream-data-dev-temporary --config rclone.conf\n",
    "\n",
    "    ./rclone ls \"remoteprod:aind-behavior-data/pose_estimation_training/DLC annotation/1051155866_524760_20200917.behavior-Shailaja-2023-06-19/videos\" --config rclone.conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
